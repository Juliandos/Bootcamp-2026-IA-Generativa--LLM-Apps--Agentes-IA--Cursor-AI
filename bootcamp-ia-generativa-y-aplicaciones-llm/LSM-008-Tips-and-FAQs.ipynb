{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSM-008: Tips and FAQs - Pro Tips and Common Questions\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Master advanced LangSmith optimization techniques\n",
    "- Troubleshoot common issues and edge cases\n",
    "- Implement best practices for enterprise deployment\n",
    "- Understand performance tuning strategies\n",
    "- Navigate advanced LangSmith features and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü Pro Tips Collection\n",
    "\n",
    "This comprehensive guide contains battle-tested tips and solutions from real-world LangSmith deployments.\n",
    "\n",
    "### üìö What's Covered\n",
    "- **Performance Optimization**: Speed up your LangSmith workflows\n",
    "- **Debugging Techniques**: Solve complex tracing issues\n",
    "- **Cost Management**: Optimize your LangSmith usage costs\n",
    "- **Enterprise Deployment**: Scale LangSmith for production\n",
    "- **Advanced Configurations**: Unlock hidden LangSmith features\n",
    "- **Troubleshooting Guide**: Fix common problems quickly\n",
    "- **Best Practices**: Proven patterns for success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Environment Setup\n",
    "\n",
    "Let's set up our troubleshooting and optimization environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import asyncio\n",
    "from typing import Dict, List, Optional, Any, Union\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "from collections import defaultdict, deque\n",
    "import threading\n",
    "from contextlib import contextmanager\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# LangSmith and LangChain imports\n",
    "from langsmith import Client, traceable, RunTree\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Diagnostic and monitoring utilities\n",
    "import requests\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import uuid\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment with optimization settings\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"tips-and-faqs-demo\"\n",
    "\n",
    "# Performance optimization settings\n",
    "os.environ[\"LANGSMITH_BATCH_SIZE\"] = \"10\"  # Batch traces for better performance\n",
    "os.environ[\"LANGSMITH_SAMPLE_RATE\"] = \"1.0\"  # Sample all traces (adjust for production)\n",
    "\n",
    "# Initialize clients with optimizations\n",
    "client = Client()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.3)\n",
    "\n",
    "# Configure logging for troubleshooting\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Pro tips environment configured with optimizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Optimization Tips\n",
    "\n",
    "Let's explore advanced techniques to optimize LangSmith performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangSmithOptimizer:\n",
    "    \"\"\"Advanced optimization utilities for LangSmith\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.performance_cache = {}\n",
    "        self.trace_buffer = deque(maxlen=100)\n",
    "        self.optimization_stats = defaultdict(int)\n",
    "    \n",
    "    @contextmanager\n",
    "    def performance_profiler(self, operation_name: str):\n",
    "        \"\"\"Pro Tip #1: Profile LangSmith operations for optimization\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            print(f\"üîç Performance Profile: {operation_name}\")\n",
    "            print(f\"   Duration: {duration:.3f}s\")\n",
    "            \n",
    "            # Store for analysis\n",
    "            self.performance_cache[operation_name] = {\n",
    "                'duration': duration,\n",
    "                'timestamp': datetime.now()\n",
    "            }\n",
    "    \n",
    "    def batch_trace_optimization(self, traces: List[Dict[str, Any]], batch_size: int = 10):\n",
    "        \"\"\"Pro Tip #2: Batch trace submissions for better performance\"\"\"\n",
    "        print(f\"üì¶ Batching {len(traces)} traces in groups of {batch_size}\")\n",
    "        \n",
    "        batched_traces = []\n",
    "        for i in range(0, len(traces), batch_size):\n",
    "            batch = traces[i:i + batch_size]\n",
    "            batched_traces.append(batch)\n",
    "        \n",
    "        print(f\"‚úÖ Created {len(batched_traces)} batches for optimized submission\")\n",
    "        return batched_traces\n",
    "    \n",
    "    @traceable(name=\"optimized_llm_call\")\n",
    "    def cached_llm_call(self, prompt: str, cache_ttl: int = 3600) -> str:\n",
    "        \"\"\"Pro Tip #3: Implement intelligent caching for repeated queries\"\"\"\n",
    "        # Create cache key\n",
    "        cache_key = hashlib.md5(prompt.encode()).hexdigest()\n",
    "        \n",
    "        # Check cache\n",
    "        if cache_key in self.performance_cache:\n",
    "            cached_data = self.performance_cache[cache_key]\n",
    "            if hasattr(cached_data, 'get') and 'response' in cached_data:\n",
    "                if (datetime.now() - cached_data['timestamp']).seconds < cache_ttl:\n",
    "                    print(f\"üíæ Cache hit for prompt hash: {cache_key[:8]}...\")\n",
    "                    self.optimization_stats['cache_hits'] += 1\n",
    "                    return cached_data['response']\n",
    "        \n",
    "        # Cache miss - make actual call\n",
    "        print(f\"üîÑ Cache miss - making LLM call for: {cache_key[:8]}...\")\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        # Cache the response\n",
    "        self.performance_cache[cache_key] = {\n",
    "            'response': response.content,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        \n",
    "        self.optimization_stats['cache_misses'] += 1\n",
    "        return response.content\n",
    "    \n",
    "    def smart_sampling_strategy(self, trace_importance: str = \"normal\") -> bool:\n",
    "        \"\"\"Pro Tip #4: Implement smart sampling to reduce costs while maintaining visibility\"\"\"\n",
    "        sampling_rates = {\n",
    "            \"critical\": 1.0,    # Always trace critical operations\n",
    "            \"important\": 0.5,   # Sample 50% of important operations\n",
    "            \"normal\": 0.1,      # Sample 10% of normal operations\n",
    "            \"debug\": 0.01       # Sample 1% of debug operations\n",
    "        }\n",
    "        \n",
    "        rate = sampling_rates.get(trace_importance, 0.1)\n",
    "        should_trace = time.time() % 1 < rate\n",
    "        \n",
    "        if should_trace:\n",
    "            self.optimization_stats['traces_sampled'] += 1\n",
    "        else:\n",
    "            self.optimization_stats['traces_skipped'] += 1\n",
    "        \n",
    "        return should_trace\n",
    "    \n",
    "    def get_optimization_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate optimization performance report\"\"\"\n",
    "        cache_total = self.optimization_stats['cache_hits'] + self.optimization_stats['cache_misses']\n",
    "        cache_hit_rate = self.optimization_stats['cache_hits'] / cache_total if cache_total > 0 else 0\n",
    "        \n",
    "        trace_total = self.optimization_stats['traces_sampled'] + self.optimization_stats['traces_skipped']\n",
    "        sampling_rate = self.optimization_stats['traces_sampled'] / trace_total if trace_total > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'cache_performance': {\n",
    "                'hit_rate': cache_hit_rate,\n",
    "                'total_calls': cache_total,\n",
    "                'hits': self.optimization_stats['cache_hits'],\n",
    "                'misses': self.optimization_stats['cache_misses']\n",
    "            },\n",
    "            'sampling_performance': {\n",
    "                'sampling_rate': sampling_rate,\n",
    "                'total_operations': trace_total,\n",
    "                'traces_captured': self.optimization_stats['traces_sampled'],\n",
    "                'traces_skipped': self.optimization_stats['traces_skipped']\n",
    "            },\n",
    "            'performance_profiles': len([k for k in self.performance_cache.keys() if k != 'cache_key'])\n",
    "        }\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = LangSmithOptimizer()\n",
    "print(\"‚ö° LangSmith optimizer initialized with pro tips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Performance Optimization Demo\n",
    "\n",
    "Let's test our optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Testing Performance Optimization Techniques\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 1: Performance Profiling\n",
    "print(\"\\n1. üîç Performance Profiling Demo\")\n",
    "with optimizer.performance_profiler(\"llm_batch_processing\"):\n",
    "    # Simulate batch processing\n",
    "    for i in range(3):\n",
    "        response = llm.invoke([HumanMessage(content=f\"Generate a short summary about topic {i+1}\")])\n",
    "        time.sleep(0.1)  # Simulate processing\n",
    "\n",
    "# Test 2: Caching Demo\n",
    "print(\"\\n2. üíæ Intelligent Caching Demo\")\n",
    "test_prompts = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain artificial intelligence\",\n",
    "    \"What is machine learning?\",  # Repeat to demonstrate cache\n",
    "    \"Define deep learning\",\n",
    "    \"What is machine learning?\"   # Another repeat\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\nCall {i}: {prompt}\")\n",
    "    with optimizer.performance_profiler(f\"cached_call_{i}\"):\n",
    "        response = optimizer.cached_llm_call(prompt)\n",
    "        print(f\"Response length: {len(response)} characters\")\n",
    "\n",
    "# Test 3: Smart Sampling\n",
    "print(\"\\n3. üéØ Smart Sampling Strategy Demo\")\n",
    "importance_levels = [\"critical\", \"important\", \"normal\", \"debug\"] * 5\n",
    "\n",
    "for level in importance_levels:\n",
    "    should_trace = optimizer.smart_sampling_strategy(level)\n",
    "    status = \"‚úÖ TRACE\" if should_trace else \"‚è≠Ô∏è  SKIP\"\n",
    "    # Only show some results to avoid spam\n",
    "    if level == \"critical\" or (level == \"important\" and should_trace):\n",
    "        print(f\"{status} - {level} operation\")\n",
    "\n",
    "# Display optimization report\n",
    "print(\"\\nüìä Optimization Performance Report\")\n",
    "print(\"=\" * 40)\n",
    "report = optimizer.get_optimization_report()\n",
    "\n",
    "print(f\"\\nüíæ Cache Performance:\")\n",
    "print(f\"   Hit Rate: {report['cache_performance']['hit_rate']:.1%}\")\n",
    "print(f\"   Total Calls: {report['cache_performance']['total_calls']}\")\n",
    "print(f\"   Hits: {report['cache_performance']['hits']}\")\n",
    "print(f\"   Misses: {report['cache_performance']['misses']}\")\n",
    "\n",
    "print(f\"\\nüéØ Sampling Performance:\")\n",
    "print(f\"   Sampling Rate: {report['sampling_performance']['sampling_rate']:.1%}\")\n",
    "print(f\"   Operations: {report['sampling_performance']['total_operations']}\")\n",
    "print(f\"   Traced: {report['sampling_performance']['traces_captured']}\")\n",
    "print(f\"   Skipped: {report['sampling_performance']['traces_skipped']}\")\n",
    "\n",
    "print(f\"\\nüîß System Metrics:\")\n",
    "print(f\"   Performance Profiles: {report['performance_profiles']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Performance optimization demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêõ Advanced Troubleshooting Techniques\n",
    "\n",
    "Let's build comprehensive debugging and troubleshooting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangSmithDiagnostic:\n",
    "    \"\"\"Advanced diagnostic tools for LangSmith troubleshooting\"\"\"\n",
    "    \n",
    "    def __init__(self, client: Client):\n",
    "        self.client = client\n",
    "        self.diagnostic_history = deque(maxlen=100)\n",
    "        self.error_patterns = defaultdict(int)\n",
    "        \n",
    "    def health_check(self) -> Dict[str, Any]:\n",
    "        \"\"\"Pro Tip #5: Comprehensive LangSmith health check\"\"\"\n",
    "        print(\"üè• Running LangSmith Health Check...\")\n",
    "        \n",
    "        health_report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'environment_variables': {},\n",
    "            'api_connectivity': {},\n",
    "            'configuration_issues': [],\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        # Check environment variables\n",
    "        required_vars = ['LANGCHAIN_TRACING_V2', 'LANGSMITH_API_KEY', 'LANGCHAIN_PROJECT']\n",
    "        for var in required_vars:\n",
    "            value = os.getenv(var)\n",
    "            health_report['environment_variables'][var] = {\n",
    "                'set': value is not None,\n",
    "                'value': value[:10] + '...' if value and len(value) > 10 else value\n",
    "            }\n",
    "            \n",
    "            if not value:\n",
    "                health_report['configuration_issues'].append(f\"Missing required environment variable: {var}\")\n",
    "        \n",
    "        # Test API connectivity (simulated)\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            api_latency = time.time() - start_time\n",
    "            \n",
    "            health_report['api_connectivity'] = {\n",
    "                'status': 'healthy',\n",
    "                'latency_ms': api_latency * 1000,\n",
    "                'endpoint': 'https://api.smith.langchain.com'\n",
    "            }\n",
    "            \n",
    "            if api_latency > 2.0:\n",
    "                health_report['recommendations'].append('API latency is high - check network connection')\n",
    "                \n",
    "        except Exception as e:\n",
    "            health_report['api_connectivity'] = {\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            health_report['configuration_issues'].append(f'API connectivity issue: {str(e)}')\n",
    "        \n",
    "        # Generate recommendations\n",
    "        if not health_report['configuration_issues']:\n",
    "            health_report['recommendations'].append('‚úÖ Configuration looks healthy')\n",
    "        else:\n",
    "            health_report['recommendations'].append('üîß Configuration issues detected - see details above')\n",
    "        \n",
    "        # Store diagnostic\n",
    "        self.diagnostic_history.append(health_report)\n",
    "        \n",
    "        return health_report\n",
    "    \n",
    "    @contextmanager\n",
    "    def error_capture_context(self, operation_name: str):\n",
    "        \"\"\"Pro Tip #6: Capture and analyze errors with full context\"\"\"\n",
    "        try:\n",
    "            yield\n",
    "        except Exception as e:\n",
    "            error_info = {\n",
    "                'operation': operation_name,\n",
    "                'error_type': type(e).__name__,\n",
    "                'error_message': str(e),\n",
    "                'timestamp': datetime.now(),\n",
    "                'traceback': traceback.format_exc()\n",
    "            }\n",
    "            \n",
    "            # Pattern analysis\n",
    "            error_pattern = f\"{type(e).__name__}:{operation_name}\"\n",
    "            self.error_patterns[error_pattern] += 1\n",
    "            \n",
    "            print(f\"‚ùå Error captured in {operation_name}:\")\n",
    "            print(f\"   Type: {type(e).__name__}\")\n",
    "            print(f\"   Message: {str(e)}\")\n",
    "            print(f\"   Pattern count: {self.error_patterns[error_pattern]}\")\n",
    "            \n",
    "            self.diagnostic_history.append(error_info)\n",
    "            \n",
    "            # Re-raise the exception\n",
    "            raise\n",
    "    \n",
    "    def trace_debugging_helper(self) -> Dict[str, Any]:\n",
    "        \"\"\"Pro Tip #7: Debug missing or incomplete traces\"\"\"\n",
    "        debug_info = {\n",
    "            'trace_debugging': True,\n",
    "            'checks_performed': [],\n",
    "            'issues_found': [],\n",
    "            'recommendations': []\n",
    "        }\n",
    "        \n",
    "        # Check environment variables\n",
    "        debug_info['checks_performed'].append('environment_variables')\n",
    "        if not os.getenv('LANGCHAIN_TRACING_V2'):\n",
    "            debug_info['issues_found'].append('LANGCHAIN_TRACING_V2 not set to \"true\"')\n",
    "            debug_info['recommendations'].append('Set LANGCHAIN_TRACING_V2=\"true\"')\n",
    "        \n",
    "        # Check API key\n",
    "        debug_info['checks_performed'].append('api_key_validation')\n",
    "        api_key = os.getenv('LANGSMITH_API_KEY')\n",
    "        if not api_key:\n",
    "            debug_info['issues_found'].append('LANGSMITH_API_KEY not set')\n",
    "            debug_info['recommendations'].append('Set LANGSMITH_API_KEY with your API key')\n",
    "        elif len(api_key) < 10:\n",
    "            debug_info['issues_found'].append('API key appears too short')\n",
    "            debug_info['recommendations'].append('Verify API key is complete and valid')\n",
    "        \n",
    "        return debug_info\n",
    "    \n",
    "    def generate_diagnostic_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive diagnostic report\"\"\"\n",
    "        return {\n",
    "            'health_check': self.health_check(),\n",
    "            'trace_debugging': self.trace_debugging_helper(),\n",
    "            'error_patterns': dict(self.error_patterns),\n",
    "            'diagnostic_history_count': len(self.diagnostic_history)\n",
    "        }\n",
    "\n",
    "# Initialize diagnostic tools\n",
    "diagnostic = LangSmithDiagnostic(client)\n",
    "print(\"üêõ Advanced diagnostic tools initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Troubleshooting Demo\n",
    "\n",
    "Let's test our diagnostic and troubleshooting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Testing Advanced Troubleshooting Tools\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 1: Health Check\n",
    "print(\"\\n1. üè• Comprehensive Health Check\")\n",
    "health_report = diagnostic.health_check()\n",
    "\n",
    "print(f\"\\nüìä Health Check Results:\")\n",
    "print(f\"Timestamp: {health_report['timestamp']}\")\n",
    "\n",
    "print(f\"\\nüåç Environment Variables:\")\n",
    "for var, info in health_report['environment_variables'].items():\n",
    "    status = \"‚úÖ\" if info['set'] else \"‚ùå\"\n",
    "    print(f\"   {status} {var}: {'Set' if info['set'] else 'Not set'}\")\n",
    "\n",
    "print(f\"\\nüåê API Connectivity:\")\n",
    "api_status = health_report['api_connectivity']\n",
    "if api_status.get('status') == 'healthy':\n",
    "    print(f\"   ‚úÖ Status: {api_status['status']}\")\n",
    "    print(f\"   ‚ö° Latency: {api_status.get('latency_ms', 0):.1f}ms\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Status: {api_status.get('status', 'unknown')}\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "for rec in health_report['recommendations']:\n",
    "    print(f\"   ‚Ä¢ {rec}\")\n",
    "\n",
    "# Test 2: Error Capture Context\n",
    "print(\"\\n2. üéØ Error Capture and Analysis\")\n",
    "print(\"Testing error capture with intentional errors...\")\n",
    "\n",
    "# Simulate different types of errors\n",
    "error_scenarios = [\n",
    "    (\"division_by_zero\", lambda: 1/0),\n",
    "    (\"key_error\", lambda: {}['missing_key'])\n",
    "]\n",
    "\n",
    "for scenario_name, error_func in error_scenarios:\n",
    "    try:\n",
    "        with diagnostic.error_capture_context(scenario_name):\n",
    "            error_func()\n",
    "    except Exception:\n",
    "        pass  # Expected - error was captured and logged\n",
    "\n",
    "# Test 3: Trace Debugging\n",
    "print(\"\\n3. üîç Trace Debugging Helper\")\n",
    "debug_info = diagnostic.trace_debugging_helper()\n",
    "\n",
    "print(f\"\\nüîé Debugging Checks Performed:\")\n",
    "for check in debug_info['checks_performed']:\n",
    "    print(f\"   ‚úì {check.replace('_', ' ').title()}\")\n",
    "\n",
    "if debug_info['issues_found']:\n",
    "    print(f\"\\n‚ö†Ô∏è  Issues Found:\")\n",
    "    for issue in debug_info['issues_found']:\n",
    "        print(f\"   ‚Ä¢ {issue}\")\n",
    "        \n",
    "    print(f\"\\nüîß Recommendations:\")\n",
    "    for rec in debug_info['recommendations']:\n",
    "        print(f\"   ‚Ä¢ {rec}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No issues found in trace configuration\")\n",
    "\n",
    "# Generate comprehensive diagnostic report\n",
    "print(\"\\nüìã Comprehensive Diagnostic Summary\")\n",
    "full_report = diagnostic.generate_diagnostic_report()\n",
    "\n",
    "print(f\"\\nüìä Diagnostic Summary:\")\n",
    "print(f\"   Error Patterns Detected: {len(full_report['error_patterns'])}\")\n",
    "print(f\"   Diagnostic History Entries: {full_report['diagnostic_history_count']}\")\n",
    "health_issues = full_report['health_check']['configuration_issues']\n",
    "print(f\"   Health Status: {'‚úÖ Healthy' if not health_issues else '‚ö†Ô∏è Issues Detected'}\")\n",
    "\n",
    "if full_report['error_patterns']:\n",
    "    print(f\"\\nüîç Error Patterns:\")\n",
    "    for pattern, count in full_report['error_patterns'].items():\n",
    "        print(f\"   ‚Ä¢ {pattern}: {count} occurrences\")\n",
    "\n",
    "print(\"\\n‚úÖ Advanced troubleshooting demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Frequently Asked Questions\n",
    "\n",
    "Comprehensive answers to the most common LangSmith questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangSmithFAQ:\n",
    "    \"\"\"Comprehensive FAQ system with interactive answers\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.faq_database = {\n",
    "            'tracing_not_working': {\n",
    "                'question': 'My traces are not appearing in LangSmith. What should I check?',\n",
    "                'category': 'troubleshooting',\n",
    "                'answer': '''Most tracing issues are due to configuration problems. Check these in order:\n",
    "                \n",
    "1. Environment Variables:\n",
    "   - Set LANGCHAIN_TRACING_V2=\"true\"\n",
    "   - Set LANGSMITH_API_KEY=\"your_api_key\"\n",
    "   - Set LANGCHAIN_PROJECT=\"your_project_name\"\n",
    "\n",
    "2. API Key Validation:\n",
    "   - Verify your API key is correct and active\n",
    "   - Check it has the necessary permissions\n",
    "\n",
    "3. Network Connectivity:\n",
    "   - Ensure you can reach api.smith.langchain.com\n",
    "   - Check firewall and proxy settings\n",
    "\n",
    "4. Code Integration:\n",
    "   - Make sure you're using @traceable decorator or RunTree\n",
    "   - Verify LangChain version compatibility'''\n",
    "            },\n",
    "            'high_costs': {\n",
    "                'question': 'My LangSmith costs are higher than expected. How can I reduce them?',\n",
    "                'category': 'cost_optimization',\n",
    "                'answer': '''High LangSmith costs usually come from excessive trace volume. Here's how to optimize:\n",
    "                \n",
    "1. Implement Smart Sampling:\n",
    "   - Use different sampling rates for different trace types\n",
    "   - Always sample errors and quality issues\n",
    "   - Reduce sampling for routine operations\n",
    "\n",
    "2. Optimize Trace Frequency:\n",
    "   - Don't trace every single operation\n",
    "   - Focus on critical paths and user-facing interactions\n",
    "   - Use batch processing for bulk operations\n",
    "\n",
    "3. Data Retention Management:\n",
    "   - Reduce retention period for non-critical data\n",
    "   - Archive or export old traces if needed'''\n",
    "            },\n",
    "            'slow_performance': {\n",
    "                'question': 'LangSmith is making my application slow. How can I optimize performance?',\n",
    "                'category': 'performance',\n",
    "                'answer': '''LangSmith should have minimal performance impact when configured correctly:\n",
    "                \n",
    "1. Async Trace Submission:\n",
    "   - Traces are submitted asynchronously by default\n",
    "   - Ensure you're not blocking on trace operations\n",
    "\n",
    "2. Batch Processing:\n",
    "   - Use batching for bulk operations\n",
    "   - Set appropriate batch sizes (10-50 traces)\n",
    "\n",
    "3. Reduce Trace Payload Size:\n",
    "   - Avoid including large data objects in traces\n",
    "   - Use metadata references instead of full content\n",
    "\n",
    "4. Local Caching:\n",
    "   - Implement local caching for repeated operations\n",
    "   - Cache evaluation results when appropriate'''\n",
    "            }\n",
    "        }\n",
    "        self.search_history = deque(maxlen=50)\n",
    "    \n",
    "    def search_faq(self, query: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search FAQ database for relevant questions\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        results = []\n",
    "        \n",
    "        for faq_id, faq_data in self.faq_database.items():\n",
    "            # Simple keyword matching\n",
    "            question_lower = faq_data['question'].lower()\n",
    "            answer_lower = faq_data['answer'].lower()\n",
    "            \n",
    "            score = 0\n",
    "            query_words = query_lower.split()\n",
    "            \n",
    "            for word in query_words:\n",
    "                if word in question_lower:\n",
    "                    score += 2\n",
    "                elif word in answer_lower:\n",
    "                    score += 1\n",
    "            \n",
    "            if score > 0:\n",
    "                results.append({\n",
    "                    'id': faq_id,\n",
    "                    'score': score,\n",
    "                    'question': faq_data['question'],\n",
    "                    'category': faq_data['category']\n",
    "                })\n",
    "        \n",
    "        # Sort by relevance score\n",
    "        results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        # Store search\n",
    "        self.search_history.append({\n",
    "            'query': query,\n",
    "            'results_count': len(results),\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "        \n",
    "        return results[:5]  # Return top 5 matches\n",
    "    \n",
    "    def get_detailed_answer(self, faq_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get detailed answer for a specific FAQ\"\"\"\n",
    "        if faq_id not in self.faq_database:\n",
    "            return {'error': 'FAQ not found'}\n",
    "        \n",
    "        faq = self.faq_database[faq_id]\n",
    "        return {\n",
    "            'question': faq['question'],\n",
    "            'category': faq['category'],\n",
    "            'answer': faq['answer'].strip()\n",
    "        }\n",
    "    \n",
    "    def get_categories(self) -> Dict[str, int]:\n",
    "        \"\"\"Get FAQ categories and counts\"\"\"\n",
    "        categories = defaultdict(int)\n",
    "        for faq in self.faq_database.values():\n",
    "            categories[faq['category']] += 1\n",
    "        return dict(categories)\n",
    "\n",
    "# Initialize FAQ system\n",
    "faq_system = LangSmithFAQ()\n",
    "print(\"‚ùì LangSmith FAQ system initialized\")\n",
    "print(f\"   üìö {len(faq_system.faq_database)} FAQs available\")\n",
    "print(f\"   üè∑Ô∏è  Categories: {', '.join(faq_system.get_categories().keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Interactive FAQ Demo\n",
    "\n",
    "Let's test our interactive FAQ system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ùì Testing Interactive FAQ System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test search queries\n",
    "test_queries = [\n",
    "    \"traces not showing\",\n",
    "    \"expensive costs\",\n",
    "    \"slow performance\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nüîç Searching for: '{query}'\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    results = faq_system.search_faq(query)\n",
    "    \n",
    "    if results:\n",
    "        print(f\"Found {len(results)} relevant FAQs:\")\n",
    "        for i, result in enumerate(results[:2], 1):  # Show top 2\n",
    "            print(f\"\\n{i}. [{result['category'].title()}] {result['question']}\")\n",
    "            print(f\"   Relevance score: {result['score']}\")\n",
    "            \n",
    "            # Show detailed answer for the most relevant result\n",
    "            if i == 1:\n",
    "                print(f\"\\nüìñ Detailed Answer:\")\n",
    "                detailed = faq_system.get_detailed_answer(result['id'])\n",
    "                \n",
    "                # Show first few lines of the answer\n",
    "                answer_lines = detailed['answer'].split('\\n')[:5]\n",
    "                for line in answer_lines:\n",
    "                    if line.strip():\n",
    "                        print(f\"   {line.strip()}\")\n",
    "    else:\n",
    "        print(\"No relevant FAQs found for this query.\")\n",
    "\n",
    "print(\"\\n‚úÖ Interactive FAQ system demonstration completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Quick Reference Guide\n",
    "\n",
    "Essential commands and configurations for daily LangSmith usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_quick_reference():\n",
    "    \"\"\"Display quick reference guide for LangSmith\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ LANGSMITH QUICK REFERENCE GUIDE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Essential Environment Variables\n",
    "    print(\"\\nüåç ESSENTIAL ENVIRONMENT VARIABLES\")\n",
    "    print(\"-\" * 40)\n",
    "    env_vars = {\n",
    "        'LANGCHAIN_TRACING_V2': '\"true\" - Enable tracing',\n",
    "        'LANGSMITH_API_KEY': '\"your_api_key\" - Your LangSmith API key',\n",
    "        'LANGCHAIN_PROJECT': '\"project_name\" - Organize traces by project',\n",
    "        'LANGSMITH_SAMPLE_RATE': '\"1.0\" - Sample rate (0.0-1.0)',\n",
    "        'LANGSMITH_BATCH_SIZE': '\"10\" - Batch size for trace submission'\n",
    "    }\n",
    "    \n",
    "    for var, description in env_vars.items():\n",
    "        print(f\"{var}={description}\")\n",
    "    \n",
    "    # Quick Setup Commands\n",
    "    print(\"\\n‚ö° QUICK SETUP COMMANDS\")\n",
    "    print(\"-\" * 30)\n",
    "    setup_commands = [\n",
    "        \"# Install LangSmith\",\n",
    "        \"pip install langsmith langchain\",\n",
    "        \"\",\n",
    "        \"# Set environment variables (Linux/Mac)\",\n",
    "        'export LANGCHAIN_TRACING_V2=\"true\"',\n",
    "        'export LANGSMITH_API_KEY=\"your_api_key\"',\n",
    "        'export LANGCHAIN_PROJECT=\"my_project\"'\n",
    "    ]\n",
    "    \n",
    "    for cmd in setup_commands:\n",
    "        print(cmd)\n",
    "    \n",
    "    # Common Troubleshooting\n",
    "    print(\"\\nüîß COMMON TROUBLESHOOTING\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    troubleshooting = [\n",
    "        \"‚ùå No traces appearing:\",\n",
    "        \"   ‚Ä¢ Check LANGCHAIN_TRACING_V2=\\\"true\\\"\",\n",
    "        \"   ‚Ä¢ Verify API key is set and valid\",\n",
    "        \"   ‚Ä¢ Ensure project name is set\",\n",
    "        \"   ‚Ä¢ Check network connectivity\",\n",
    "        \"\",\n",
    "        \"üí∞ High costs:\",\n",
    "        \"   ‚Ä¢ Implement sampling (LANGSMITH_SAMPLE_RATE)\",\n",
    "        \"   ‚Ä¢ Reduce trace frequency\",\n",
    "        \"   ‚Ä¢ Optimize data retention\",\n",
    "        \"\",\n",
    "        \"üêå Slow performance:\",\n",
    "        \"   ‚Ä¢ Enable async trace submission\",\n",
    "        \"   ‚Ä¢ Use batching for bulk operations\",\n",
    "        \"   ‚Ä¢ Reduce trace payload size\"\n",
    "    ]\n",
    "    \n",
    "    for item in troubleshooting:\n",
    "        print(item)\n",
    "    \n",
    "    # Useful Links\n",
    "    print(\"\\nüîó USEFUL LINKS\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    links = [\n",
    "        \"üìñ Documentation: https://docs.smith.langchain.com/\",\n",
    "        \"üåê LangSmith App: https://smith.langchain.com/\",\n",
    "        \"üíª GitHub: https://github.com/langchain-ai/langsmith-sdk\",\n",
    "        \"üí¨ Community: https://discord.gg/langchain\"\n",
    "    ]\n",
    "    \n",
    "    for link in links:\n",
    "        print(link)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üí° Pro Tip: Bookmark this reference for quick access to essential LangSmith patterns!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Display the quick reference guide\n",
    "display_quick_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the entire LangSmith 2025 mastery series! Here's everything you've accomplished:\n",
    "\n",
    "### ‚úÖ Complete Learning Journey\n",
    "- **LSM-001**: Mastered LangSmith 2025 fundamentals and new features\n",
    "- **LSM-002**: Built your first production-ready LangSmith project\n",
    "- **LSM-003**: Achieved deep observability mastery with advanced tracing\n",
    "- **LSM-004**: Built robust evaluation pipelines and quality assurance\n",
    "- **LSM-005**: Mastered collaborative prompt engineering and version control\n",
    "- **LSM-006**: Implemented enterprise-grade production monitoring\n",
    "- **LSM-007**: Built complex multi-agent systems and advanced patterns\n",
    "- **LSM-008**: Gained expert troubleshooting and optimization skills\n",
    "\n",
    "### üõ†Ô∏è Advanced Skills Mastered\n",
    "- **Performance Optimization**: Smart sampling, caching, and batch processing\n",
    "- **Advanced Troubleshooting**: Comprehensive diagnostic tools and error analysis\n",
    "- **Cost Management**: Budget forecasting, anomaly detection, and optimization\n",
    "- **Production Deployment**: Enterprise-ready configurations and monitoring\n",
    "- **Custom Extensions**: Built specialized evaluators and integrations\n",
    "\n",
    "### üìä Key Techniques You Can Apply\n",
    "1. **Intelligent Sampling Strategies** for cost optimization\n",
    "2. **Comprehensive Error Handling** with full context capture\n",
    "3. **Performance Profiling** and bottleneck identification\n",
    "4. **Advanced Troubleshooting** with automated diagnostics\n",
    "5. **Production-Ready Patterns** for enterprise deployment\n",
    "\n",
    "### üöÄ What's Next?\n",
    "\n",
    "1. **Apply Your Skills**:\n",
    "   - Implement these patterns in your real projects\n",
    "   - Start with basic tracing and gradually add sophisticated features\n",
    "   - Use the quick reference guide for daily development\n",
    "\n",
    "2. **Stay Updated**:\n",
    "   - Follow LangSmith's latest features and updates\n",
    "   - Join the community and share your experiences\n",
    "   - Contribute to open-source LangSmith tools and examples\n",
    "\n",
    "### üèÜ You're Now a LangSmith Expert!\n",
    "\n",
    "You have the knowledge and tools to:\n",
    "- Build and monitor sophisticated LLM applications\n",
    "- Troubleshoot complex issues with confidence\n",
    "- Optimize performance and costs effectively\n",
    "- Deploy enterprise-grade LangSmith solutions\n",
    "- Lead LangSmith adoption in your organization\n",
    "\n",
    "**Thank you for completing this comprehensive LangSmith journey!** üéì\n",
    "\n",
    "**Happy building with LangSmith!** üöÄ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}