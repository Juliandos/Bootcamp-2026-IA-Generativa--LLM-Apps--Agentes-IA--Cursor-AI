{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# Modern RAG Step 3B: Backend Integration & Complete Application (2025)\n",
        "\n",
        "This notebook explains the backend integration changes needed for Step 3 and how to run the complete modern RAG chat application.\n",
        "\n",
        "## Step 3 Backend Changes (Minimal but Essential)\n",
        "\n",
        "Step 3 builds on the modern Step 2 backend with just **two small additions**:\n",
        "1. **CORS Middleware** - Enable frontend-backend communication\n",
        "2. **Static File Serving** - Allow PDF downloads from source links\n",
        "\n",
        "These changes transform the backend from a standalone API to a full-stack application server."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cors-middleware",
      "metadata": {},
      "source": [
        "## 1. CORS Middleware: Enabling Frontend Communication\n",
        "\n",
        "### What is CORS?\n",
        "CORS (Cross-Origin Resource Sharing) is a security feature built into web browsers. By default, browsers block requests from one domain (like `localhost:3000` where React runs) to another domain (like `localhost:8000` where our API runs).\n",
        "\n",
        "### The Problem Without CORS\n",
        "```javascript\n",
        "// This would fail with CORS error:\n",
        "fetch('http://localhost:8000/stream', {\n",
        "  method: 'POST',\n",
        "  // ... other options\n",
        "});\n",
        "// ‚ùå Error: CORS policy blocks this request\n",
        "```\n",
        "\n",
        "### The Solution: Add CORS Middleware\n",
        "```python\n",
        "# In server.py\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\n",
        "        \"http://localhost:3000\"  # React development server\n",
        "    ],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],      # Allow all HTTP methods (GET, POST, etc.)\n",
        "    allow_headers=[\"*\"],      # Allow all headers\n",
        ")\n",
        "```\n",
        "\n",
        "### What Each Setting Does\n",
        "- **`allow_origins`**: Which domains can make requests to our API\n",
        "- **`allow_credentials`**: Whether to include cookies/auth in requests\n",
        "- **`allow_methods`**: Which HTTP methods are allowed (GET, POST, etc.)\n",
        "- **`allow_headers`**: Which headers can be included in requests\n",
        "\n",
        "### Security Note\n",
        "In development, we allow `localhost:3000`. In production, you'd specify your actual domain:\n",
        "```python\n",
        "allow_origins=[\"https://yourdomain.com\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "static-files",
      "metadata": {},
      "source": [
        "## 2. Static File Serving: PDF Downloads\n",
        "\n",
        "### The Need for Static Files\n",
        "When the AI responds with source documents, users want to click on the source links and download/view the actual PDF files. We need to serve these files through our FastAPI server.\n",
        "\n",
        "### Adding Static File Support\n",
        "```python\n",
        "# In server.py\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "\n",
        "# Mount the PDF documents directory\n",
        "app.mount(\"/static\", StaticFiles(directory=\"./pdf-documents\"), name=\"static\")\n",
        "```\n",
        "\n",
        "### How It Works\n",
        "This creates a mapping:\n",
        "- **Directory**: `./pdf-documents/` (where PDFs are stored)\n",
        "- **URL Path**: `/static/` (how they're accessed via HTTP)\n",
        "- **Example**: `./pdf-documents/John_F_Kennedy.pdf` becomes `http://localhost:8000/static/John_F_Kennedy.pdf`\n",
        "\n",
        "### Frontend Integration\n",
        "```tsx\n",
        "// In App.tsx, source links become:\n",
        "<a\n",
        "  href={`http://localhost:8000/static/${encodeURIComponent(formatSource(source))}`}\n",
        "  target=\"_blank\"\n",
        "  download\n",
        ">\n",
        "  {formatSource(source)}\n",
        "</a>\n",
        "```\n",
        "\n",
        "### Security Considerations\n",
        "- **Directory Restriction**: Only files in `pdf-documents/` are accessible\n",
        "- **Read-Only**: Users can download but not upload or modify files\n",
        "- **FastAPI Validation**: All requests go through FastAPI's security layer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "complete-server",
      "metadata": {},
      "source": [
        "## Complete Modern Server Configuration\n",
        "\n",
        "Here's the enhanced `server.py` with all modern features:\n",
        "\n",
        "```python\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from fastapi.responses import RedirectResponse\n",
        "from fastapi.middleware.cors import CORSMiddleware  # ‚Üê NEW\n",
        "from fastapi.staticfiles import StaticFiles          # ‚Üê NEW\n",
        "from pydantic import BaseModel\n",
        "import json\n",
        "\n",
        "from app.rag_chain import final_chain\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Modern RAG API\",\n",
        "    description=\"A modern RAG application for querying PDF documents (2025 update)\",\n",
        "    version=\"3.0.0\"  # ‚Üê Updated version\n",
        ")\n",
        "\n",
        "# NEW: CORS middleware for frontend communication\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"http://localhost:3000\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# NEW: Static file serving for PDF downloads\n",
        "app.mount(\"/static\", StaticFiles(directory=\"./pdf-documents\"), name=\"static\")\n",
        "\n",
        "# Existing endpoints from Step 2:\n",
        "# GET /              ‚Üí Redirect to docs\n",
        "# POST /query        ‚Üí Single query response\n",
        "# POST /stream       ‚Üí Streaming response (used by frontend)\n",
        "# GET /health        ‚Üí Health check\n",
        "```\n",
        "\n",
        "### Key Points\n",
        "- **Builds on Step 2**: All existing functionality preserved\n",
        "- **Minimal Changes**: Only 2 additions for frontend integration\n",
        "- **Direct FastAPI**: No LangServe (which we removed in modern steps)\n",
        "- **Production Ready**: Proper CORS and file serving configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "streaming-integration",
      "metadata": {},
      "source": [
        "## Frontend-Backend Communication Flow\n",
        "\n",
        "### 1. User Sends Message\n",
        "```tsx\n",
        "// Frontend: User types and presses Enter\n",
        "const handleSendMessage = async (message: string) => {\n",
        "  // Add user message to chat immediately\n",
        "  setMessages(prev => [...prev, {message, isUser: true}]);\n",
        "  \n",
        "  // Send to backend via streaming\n",
        "  await fetchEventSource('http://localhost:8000/stream', {\n",
        "    method: 'POST',\n",
        "    headers: {'Content-Type': 'application/json'},\n",
        "    body: JSON.stringify({question: message}),\n",
        "    // ... event handlers\n",
        "  });\n",
        "};\n",
        "```\n",
        "\n",
        "### 2. Backend Processes Request\n",
        "```python\n",
        "# Backend: /stream endpoint receives the request\n",
        "@app.post(\"/stream\")\n",
        "async def stream_query(request: QueryRequest):\n",
        "    async def generate_response():\n",
        "        # Use our modern RAG chain (from Step 2)\n",
        "        async for chunk in final_chain.astream({\"question\": request.question}):\n",
        "            yield f\"data: {json.dumps({'chunk': str(chunk)})}\n",
        "\\n\"\n",
        "    \n",
        "    return StreamingResponse(generate_response(), media_type=\"text/plain\")\n",
        "```\n",
        "\n",
        "### 3. Frontend Receives Streaming Response\n",
        "```tsx\n",
        "// Frontend: Handle each chunk as it arrives\n",
        "onmessage(event) {\n",
        "  if (event.data && event.data !== \"[DONE]\") {\n",
        "    const parsedData = JSON.parse(event.data);\n",
        "    \n",
        "    if (parsedData.chunk) {\n",
        "      // Add chunk to the growing AI response\n",
        "      setPartialMessage(parsedData.chunk);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### 4. Source Links Integration\n",
        "```tsx\n",
        "// Frontend: When sources are included\n",
        "if (chunkData.docs) {\n",
        "  const sources = chunkData.docs.map(doc => doc.metadata?.source);\n",
        "  setPartialMessage(\"\", sources);\n",
        "}\n",
        "\n",
        "// Render clickable links\n",
        "<a href={`http://localhost:8000/static/${filename}`}>\n",
        "  {filename}\n",
        "</a>\n",
        "```\n",
        "\n",
        "### Complete Flow Diagram\n",
        "```\n",
        "User Types ‚Üí Frontend State ‚Üí HTTP POST ‚Üí Backend RAG ‚Üí \n",
        "Streaming Response ‚Üí Frontend Updates ‚Üí User Sees Response ‚Üí \n",
        "Click Source ‚Üí PDF Download\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "running-application",
      "metadata": {},
      "source": [
        "## Running the Complete Application\n",
        "\n",
        "### Prerequisites\n",
        "1. **Python 3.13.3** with Poetry 2.1.4\n",
        "2. **Node.js 24.x** with npm\n",
        "3. **PostgreSQL** with PGVector extension\n",
        "4. **OpenAI API Key**\n",
        "\n",
        "### Step 1: Backend Setup\n",
        "```bash\n",
        "# Navigate to project\n",
        "cd v2-modern-step3\n",
        "\n",
        "# Set up Python environment\n",
        "pyenv virtualenv 3.13.3 rag-step3-env\n",
        "pyenv activate rag-step3-env\n",
        "\n",
        "# Install dependencies\n",
        "pip install poetry==2.1.4\n",
        "poetry install\n",
        "\n",
        "# Configure environment\n",
        "cp .env.template .env\n",
        "# Edit .env with your OpenAI API key\n",
        "\n",
        "# Load documents (if not done previously)\n",
        "cd rag-data-loader\n",
        "poetry run python rag_load_and_process.py\n",
        "cd ..\n",
        "\n",
        "# Start backend server\n",
        "poetry run uvicorn app.server:app --reload --port 8000\n",
        "```\n",
        "\n",
        "‚úÖ **Backend running**: http://localhost:8000\n",
        "‚úÖ **API docs**: http://localhost:8000/docs\n",
        "‚úÖ **Static files**: http://localhost:8000/static/\n",
        "\n",
        "### Step 2: Frontend Setup\n",
        "```bash\n",
        "# New terminal - navigate to frontend\n",
        "cd v2-modern-step3/frontend\n",
        "\n",
        "# Install dependencies\n",
        "npm install\n",
        "\n",
        "# Start development server\n",
        "npm start\n",
        "```\n",
        "\n",
        "‚úÖ **Frontend running**: http://localhost:3000\n",
        "\n",
        "### Step 3: Test the Application\n",
        "1. **Open http://localhost:3000**\n",
        "2. **Type a question**: \"Who is John F. Kennedy?\"\n",
        "3. **Press Enter** or click Send\n",
        "4. **Watch the streaming response** appear in real-time\n",
        "5. **Click source links** to download PDF documents\n",
        "\n",
        "### Expected Behavior\n",
        "- **Real-time streaming**: AI response appears word by word\n",
        "- **Message history**: Previous questions and answers stay visible\n",
        "- **Source attribution**: Links to relevant PDF documents\n",
        "- **Error handling**: Graceful failure with user feedback\n",
        "- **Keyboard shortcuts**: Enter to send, Shift+Enter for newlines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "troubleshooting",
      "metadata": {},
      "source": [
        "## Troubleshooting Common Issues\n",
        "\n",
        "### 1. CORS Errors\n",
        "**Problem**: `Access to fetch at 'http://localhost:8000/stream' from origin 'http://localhost:3000' has been blocked by CORS policy`\n",
        "\n",
        "**Solution**:\n",
        "```python\n",
        "# Ensure CORS middleware is properly configured\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"http://localhost:3000\"],  # Check this matches frontend URL\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "```\n",
        "\n",
        "### 2. Frontend Can't Connect to Backend\n",
        "**Problem**: Network errors or connection refused\n",
        "\n",
        "**Check**:\n",
        "```bash\n",
        "# Verify backend is running\n",
        "curl http://localhost:8000/health\n",
        "# Should return: {\"status\": \"healthy\", \"version\": \"3.0.0\"}\n",
        "```\n",
        "\n",
        "### 3. PDF Downloads Don't Work\n",
        "**Problem**: 404 errors when clicking source links\n",
        "\n",
        "**Check**:\n",
        "```bash\n",
        "# Verify static files are mounted\n",
        "curl http://localhost:8000/static/\n",
        "# Should list PDF files\n",
        "\n",
        "# Check PDF exists\n",
        "ls pdf-documents/\n",
        "```\n",
        "\n",
        "### 4. Streaming Doesn't Work\n",
        "**Problem**: Complete response appears at once instead of streaming\n",
        "\n",
        "**Cause**: Usually browser or proxy buffering\n",
        "\n",
        "**Debug**: Check browser developer tools Network tab for streaming response\n",
        "\n",
        "### 5. OpenAI API Errors\n",
        "**Problem**: 401 Unauthorized or rate limit errors\n",
        "\n",
        "**Check**:\n",
        "```bash\n",
        "# Verify environment variables\n",
        "echo $OPENAI_API_KEY\n",
        "\n",
        "# Test API key\n",
        "curl https://api.openai.com/v1/models \\\n",
        "  -H \"Authorization: Bearer $OPENAI_API_KEY\"\n",
        "```\n",
        "\n",
        "### 6. Database Connection Issues\n",
        "**Problem**: Can't connect to PostgreSQL\n",
        "\n",
        "**Check**:\n",
        "```bash\n",
        "# Test database connection\n",
        "psql database164 -c \"SELECT 1;\"\n",
        "\n",
        "# Verify PGVector extension\n",
        "psql database164 -c \"SELECT * FROM pg_extension WHERE extname='vector';\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "development-workflow",
      "metadata": {},
      "source": [
        "## Development Workflow\n",
        "\n",
        "### Daily Development Routine\n",
        "```bash\n",
        "# Terminal 1: Backend (leave running)\n",
        "cd v2-modern-step3\n",
        "pyenv activate rag-step3-env\n",
        "poetry run uvicorn app.server:app --reload\n",
        "\n",
        "# Terminal 2: Frontend (leave running)  \n",
        "cd v2-modern-step3/frontend\n",
        "npm start\n",
        "```\n",
        "\n",
        "### Making Changes\n",
        "- **Backend changes**: Auto-reload with `--reload` flag\n",
        "- **Frontend changes**: Hot-reload with React dev server\n",
        "- **Both servers watch for file changes automatically**\n",
        "\n",
        "### Testing Changes\n",
        "1. **Backend API**: http://localhost:8000/docs\n",
        "2. **Frontend**: http://localhost:3000\n",
        "3. **End-to-end**: Test complete chat flow\n",
        "4. **Error logs**: Check both terminal outputs\n",
        "\n",
        "### Performance Monitoring\n",
        "- **Response times**: Check browser Network tab\n",
        "- **Streaming quality**: Watch message appear in real-time\n",
        "- **Memory usage**: Monitor with Activity Monitor/Task Manager\n",
        "- **OpenAI costs**: Monitor usage in OpenAI dashboard"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deployment-considerations",
      "metadata": {},
      "source": [
        "## Production Deployment Considerations\n",
        "\n",
        "### Security Enhancements\n",
        "```python\n",
        "# Production CORS configuration\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"https://yourdomain.com\"],  # Specific domain\n",
        "    allow_credentials=False,  # Usually false in production\n",
        "    allow_methods=[\"GET\", \"POST\"],  # Specific methods only\n",
        "    allow_headers=[\"Content-Type\", \"Authorization\"],  # Specific headers\n",
        ")\n",
        "```\n",
        "\n",
        "### Environment Variables\n",
        "```bash\n",
        "# Production .env\n",
        "OPENAI_API_KEY=your_production_key\n",
        "DATABASE_URL=postgresql://user:pass@prod-host:5432/prod_db\n",
        "CORS_ORIGINS=https://yourdomain.com\n",
        "```\n",
        "\n",
        "### Additional Features to Consider\n",
        "1. **Authentication**: User login and session management\n",
        "2. **Rate Limiting**: Prevent API abuse\n",
        "3. **Logging**: Comprehensive request/response logging\n",
        "4. **Monitoring**: Health checks and error alerting\n",
        "5. **Caching**: Response caching for common queries\n",
        "6. **SSL**: HTTPS certificates for secure communication\n",
        "\n",
        "### Deployment Platforms\n",
        "- **Backend**: Railway, Render, DigitalOcean, AWS\n",
        "- **Frontend**: Vercel, Netlify, GitHub Pages\n",
        "- **Database**: Supabase, Railway PostgreSQL, AWS RDS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary",
      "metadata": {},
      "source": [
        "## Summary: Complete Modern RAG Application\n",
        "\n",
        "### üéØ **What We Achieved**\n",
        "- **Complete Chat Interface**: Real conversations with AI about PDF documents\n",
        "- **Modern Architecture**: Direct FastAPI + React 19 + Tailwind v4\n",
        "- **Real-time Streaming**: Instant response feedback with Server-Sent Events\n",
        "- **Source Attribution**: Clickable links to original documents\n",
        "- **Cost Optimization**: 95% cost reduction using modern AI models\n",
        "\n",
        "### üîß **Backend Integration (Step 3 Additions)**\n",
        "1. **CORS Middleware**: Enables frontend-backend communication\n",
        "2. **Static File Serving**: Allows PDF downloads from source links\n",
        "3. **Enhanced API**: Version 3.0.0 with full-stack capabilities\n",
        "\n",
        "### üöÄ **Modern Technology Stack**\n",
        "- **Backend**: Python 3.13.3, FastAPI 0.115.0, LangChain, OpenAI GPT-4o-mini\n",
        "- **Frontend**: React 19.0.0, TypeScript 5.9.2, Tailwind CSS 4.0.0\n",
        "- **Database**: PostgreSQL with PGVector extension\n",
        "- **Communication**: Server-Sent Events for real-time streaming\n",
        "\n",
        "### üìà **Performance Benefits**\n",
        "- **5-100x faster builds** with Tailwind CSS v4\n",
        "- **React 19 performance improvements** for smooth UX\n",
        "- **Direct FastAPI** eliminates deprecated LangServe overhead\n",
        "- **Streaming responses** for better perceived performance\n",
        "\n",
        "### üéì **Educational Value**\n",
        "Students learn:\n",
        "- **Complete full-stack development** with modern technologies\n",
        "- **Real-time communication** patterns with Server-Sent Events\n",
        "- **State management** in React with hooks\n",
        "- **API integration** and error handling\n",
        "- **Production considerations** for deployment and security\n",
        "\n",
        "### üèÜ **Final Result**\n",
        "A production-ready RAG chat application that:\n",
        "- Costs **95% less** than traditional implementations\n",
        "- Uses **2025 best practices** throughout\n",
        "- Provides **excellent user experience** with streaming responses\n",
        "- Includes **source attribution** for transparency\n",
        "- Serves as **educational foundation** for advanced features\n",
        "\n",
        "The modern RAG Step 3 demonstrates how current technologies can create powerful, cost-effective AI applications that rival commercial offerings while being accessible to beginners.\n",
        "\n",
        "---\n",
        "\n",
        "*This completes the modern RAG application series. Students now have a fully functional, cost-effective, and educationally valuable chat interface for querying PDF documents using 2025 best practices.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}