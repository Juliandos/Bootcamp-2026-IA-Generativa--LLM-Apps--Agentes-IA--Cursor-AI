{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 22: Backend AI Integration - LangChain Patterns and FastAPI Endpoints\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "\n",
    "Now it's time to add AI superpowers to your FastAPI backend! In this notebook, you'll learn how to integrate **LangChain** with your existing Todo API to create two powerful AI features:\n",
    "\n",
    "1. **üìù Text Summarization**: A general-purpose AI endpoint for summarizing any text\n",
    "2. **üé≠ Poem Generator**: Transform your todo items into creative poems using AI\n",
    "\n",
    "**The best part?** Your existing todo CRUD operations will continue working exactly as before - we're just adding new AI-powered endpoints!\n",
    "\n",
    "## üîß What We're Building\n",
    "\n",
    "**New API Endpoints:**\n",
    "- `POST /todos/summarize-text` - Summarize any text using AI\n",
    "- `POST /todos/write-poem/{id}` - Generate a poem from a specific todo\n",
    "\n",
    "**LangChain Integration:**\n",
    "- Clean, organized AI code using modern patterns\n",
    "- Reusable prompt templates\n",
    "- Proper error handling for AI operations\n",
    "\n",
    "---\n",
    "\n",
    "**üí° Key Insight**: Adding AI to existing APIs is about enhancing, not replacing. Your core CRUD functionality stays intact while AI adds new capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Installing LangChain and Dependencies\n",
    "\n",
    "### What We Need to Add\n",
    "\n",
    "Your existing Todo app already has most of what we need. We just need to add a few AI-specific packages:\n",
    "\n",
    "**Required Packages:**\n",
    "- `langchain==0.1.1` - Main LangChain library\n",
    "- `openai` - OpenAI API client (already included in LangChain)\n",
    "- Your existing packages stay exactly the same!\n",
    "\n",
    "### Installation Process\n",
    "\n",
    "**Step 1: Navigate to Your Backend Directory**\n",
    "```bash\n",
    "cd your-todo-app/backend\n",
    "```\n",
    "\n",
    "**Step 2: Activate Your Virtual Environment**\n",
    "```bash\n",
    "# If using Poetry (modern todo app)\n",
    "poetry shell\n",
    "\n",
    "# If using venv (original todo app)\n",
    "source venv/bin/activate  # macOS/Linux\n",
    "# OR\n",
    "venv\\Scripts\\activate     # Windows\n",
    "```\n",
    "\n",
    "**Step 3: Install LangChain**\n",
    "```bash\n",
    "# If using Poetry\n",
    "poetry add langchain==0.1.1\n",
    "\n",
    "# If using pip\n",
    "pip install langchain==0.1.1\n",
    "```\n",
    "\n",
    "**Step 4: Update Requirements (if using pip)**\n",
    "```bash\n",
    "pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "### Why This Specific LangChain Version?\n",
    "\n",
    "We're using **LangChain 0.1.1** because:\n",
    "- ‚úÖ **Stable and tested**: Known to work well with our patterns\n",
    "- ‚úÖ **Simple imports**: Uses the classic `from langchain import` syntax\n",
    "- ‚úÖ **Educational clarity**: Fewer abstractions to understand\n",
    "- ‚úÖ **Consistent results**: Same behavior across all installations\n",
    "\n",
    "**‚ö†Ô∏è Important**: LangChain updates frequently and newer versions might have different syntax. Stick with 0.1.1 for this tutorial to avoid compatibility issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Environment Configuration - Adding OpenAI API Key\n",
    "\n",
    "### Setting Up Your OpenAI API Key\n",
    "\n",
    "**Step 1: Add to Environment File**\n",
    "\n",
    "Open your `backend/.env` file and add your OpenAI API key:\n",
    "\n",
    "```bash\n",
    "# Existing environment variables (keep these!)\n",
    "DATABASE_USER=todo_user\n",
    "DATABASE_PASSWORD=todo_password\n",
    "DATABASE_HOST=localhost\n",
    "DATABASE_PORT=5432\n",
    "DATABASE_NAME=modern_todo_db\n",
    "\n",
    "# NEW: Add your OpenAI API key\n",
    "OPENAI_API_KEY=sk-your-actual-api-key-here\n",
    "```\n",
    "\n",
    "**Step 2: Verify Environment Loading**\n",
    "\n",
    "Your existing `config.py` should already handle environment variables. If you're using our modern setup, it looks like this:\n",
    "\n",
    "```python\n",
    "# config.py (should already exist)\n",
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    database_user: str\n",
    "    database_password: str\n",
    "    database_host: str\n",
    "    database_port: int\n",
    "    database_name: str\n",
    "    \n",
    "    # Add this line for OpenAI\n",
    "    openai_api_key: str = None  # Optional, with default\n",
    "    \n",
    "    model_config = ConfigDict(env_file=\".env\")\n",
    "```\n",
    "\n",
    "**Step 3: Environment Variable Security**\n",
    "\n",
    "**‚úÖ Good Practices:**\n",
    "- Keep `.env` file in `.gitignore` (should already be there)\n",
    "- Never commit API keys to version control\n",
    "- Use different keys for development and production\n",
    "\n",
    "**üîç Check Your .gitignore:**\n",
    "```\n",
    "# Should already include\n",
    ".env\n",
    "__pycache__/\n",
    "*.pyc\n",
    "```\n",
    "\n",
    "### How LangChain Will Find Your API Key\n",
    "\n",
    "LangChain automatically looks for `OPENAI_API_KEY` in your environment variables. When you create an OpenAI instance:\n",
    "\n",
    "```python\n",
    "from langchain import OpenAI\n",
    "\n",
    "# This automatically uses OPENAI_API_KEY from environment\n",
    "llm = OpenAI(temperature=0)\n",
    "```\n",
    "\n",
    "**No need to explicitly pass the key!** LangChain handles this for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding LangChain Components\n",
    "\n",
    "Before we write code, let's understand the LangChain building blocks we'll use:\n",
    "\n",
    "### 1. OpenAI LLM (Large Language Model)\n",
    "\n",
    "```python\n",
    "from langchain import OpenAI\n",
    "\n",
    "# Create an OpenAI instance\n",
    "llm = OpenAI(temperature=0)\n",
    "```\n",
    "\n",
    "**Parameters Explained:**\n",
    "- **`temperature=0`**: More focused, consistent responses (range: 0-1)\n",
    "  - `0` = very focused, predictable\n",
    "  - `1` = very creative, unpredictable\n",
    "  - `0.7` = balanced creativity (good for poems)\n",
    "\n",
    "**What This Does:**\n",
    "- Connects to OpenAI's API using your key\n",
    "- Uses GPT-3.5-turbo by default (fast and cost-effective)\n",
    "- Handles authentication automatically\n",
    "\n",
    "### 2. PromptTemplate\n",
    "\n",
    "```python\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "# Create a reusable prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Write a summary of: {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "```\n",
    "\n",
    "**Why Use Templates?**\n",
    "- **Consistency**: Same prompt format every time\n",
    "- **Reusability**: Use with different inputs\n",
    "- **Maintainability**: Change prompt in one place\n",
    "- **Testing**: Easy to test different prompt versions\n",
    "\n",
    "**Template Syntax:**\n",
    "- `{variable_name}` gets replaced with actual values\n",
    "- `input_variables` list must match template variables\n",
    "\n",
    "### 3. LLMChain\n",
    "\n",
    "```python\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Combine LLM + Prompt into a chain\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Use the chain\n",
    "result = chain.run(text=\"Your input text here\")\n",
    "```\n",
    "\n",
    "**What LLMChain Does:**\n",
    "1. Takes your input variables\n",
    "2. Fills in the prompt template\n",
    "3. Sends the complete prompt to the LLM\n",
    "4. Returns the AI's response\n",
    "\n",
    "**Benefits of Chains:**\n",
    "- **Clean code**: One line to run AI operations\n",
    "- **Error handling**: Built-in retry and error management\n",
    "- **Extensibility**: Can chain multiple operations together\n",
    "- **Debugging**: Easy to see what's being sent to AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Adding LangChain Imports to Your Existing Router\n",
    "\n",
    "### Your Current todos.py File\n",
    "\n",
    "Your existing `routers/todos.py` probably looks like this:\n",
    "\n",
    "```python\n",
    "# routers/todos.py (current)\n",
    "from typing import List\n",
    "from sqlalchemy.orm import Session\n",
    "from fastapi import APIRouter, Depends, HTTPException, status\n",
    "import schemas\n",
    "import crud\n",
    "from database import SessionLocal\n",
    "\n",
    "router = APIRouter(prefix=\"/todos\")\n",
    "\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# Your existing CRUD endpoints here...\n",
    "@router.post(\"\", status_code=status.HTTP_201_CREATED)\n",
    "def create_todo(todo: schemas.TodoRequest, db: Session = Depends(get_db)):\n",
    "    return crud.create_todo(db, todo)\n",
    "\n",
    "# ... rest of your CRUD endpoints\n",
    "```\n",
    "\n",
    "### Adding LangChain Imports\n",
    "\n",
    "**Step 1: Add New Imports**\n",
    "\n",
    "Add these imports at the top of your `routers/todos.py` file:\n",
    "\n",
    "```python\n",
    "# routers/todos.py (enhanced)\n",
    "from typing import List\n",
    "from sqlalchemy.orm import Session\n",
    "from fastapi import APIRouter, Depends, HTTPException, status\n",
    "import schemas\n",
    "import crud\n",
    "from database import SessionLocal\n",
    "\n",
    "# NEW: LangChain imports\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "router = APIRouter(prefix=\"/todos\")\n",
    "\n",
    "# Your existing functions stay exactly the same!\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# All your existing CRUD endpoints continue working...\n",
    "```\n",
    "\n",
    "**Step 2: Test the Imports**\n",
    "\n",
    "Start your server to make sure the imports work:\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "If you see any import errors:\n",
    "- Make sure you installed `langchain==0.1.1`\n",
    "- Make sure you're in the right virtual environment\n",
    "- Try restarting your terminal and activating the environment again\n",
    "\n",
    "**‚úÖ Success Signs:**\n",
    "- Server starts without errors\n",
    "- Your existing endpoints work: `http://localhost:8000/docs`\n",
    "- All your todo CRUD operations still function perfectly\n",
    "\n",
    "**üö´ No Changes to Existing Code:**\n",
    "- Your existing endpoints remain untouched\n",
    "- Your database models stay the same\n",
    "- Your CRUD functions continue working\n",
    "- Your schemas don't change\n",
    "\n",
    "We're adding AI on top of your existing, working system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Creating the Text Summarization Feature\n",
    "\n",
    "### Step 1: Set Up LangChain Components\n",
    "\n",
    "Add this code to your `routers/todos.py` file, **after** your existing CRUD endpoints:\n",
    "\n",
    "```python\n",
    "# Add this AFTER your existing CRUD endpoints\n",
    "# ==========================================\n",
    "# LANGCHAIN AI FEATURES\n",
    "# ==========================================\n",
    "\n",
    "# Initialize OpenAI LLM\n",
    "langchain_llm = OpenAI(temperature=0)\n",
    "\n",
    "# Create prompt template for summarization\n",
    "summarize_template_string = \"\"\"\n",
    "        Provide a summary for the following text:\n",
    "        {text}\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "    template=summarize_template_string,\n",
    "    input_variables=['text'],\n",
    ")\n",
    "\n",
    "# Create LLM chain for summarization\n",
    "summarize_chain = LLMChain(\n",
    "    llm=langchain_llm,\n",
    "    prompt=summarize_prompt,\n",
    ")\n",
    "```\n",
    "\n",
    "**Code Explanation:**\n",
    "\n",
    "**`langchain_llm = OpenAI(temperature=0)`**\n",
    "- Creates connection to OpenAI API\n",
    "- `temperature=0` for consistent, focused summaries\n",
    "- Uses your `OPENAI_API_KEY` automatically\n",
    "\n",
    "**`summarize_template_string`**\n",
    "- Clear, simple instruction to the AI\n",
    "- `{text}` placeholder gets replaced with actual content\n",
    "- Triple quotes for multi-line string (cleaner formatting)\n",
    "\n",
    "**`summarize_prompt = PromptTemplate(...)`**\n",
    "- Converts string template into LangChain object\n",
    "- `input_variables=['text']` specifies what can be substituted\n",
    "- Must match the `{text}` placeholder in template\n",
    "\n",
    "**`summarize_chain = LLMChain(...)`**\n",
    "- Combines the AI model with the prompt template\n",
    "- Ready-to-use chain for summarization tasks\n",
    "- Handles all the communication with OpenAI API\n",
    "\n",
    "### Step 2: Create the API Endpoint\n",
    "\n",
    "Add this endpoint **after** the LangChain setup code:\n",
    "\n",
    "```python\n",
    "# Text summarization endpoint\n",
    "@router.post('/summarize-text')\n",
    "async def summarize_text(text: str):\n",
    "    try:\n",
    "        summary = summarize_chain.run(text=text)\n",
    "        return {'summary': summary}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500, \n",
    "            detail=f\"AI summarization failed: {str(e)}\"\n",
    "        )\n",
    "```\n",
    "\n",
    "**Endpoint Explanation:**\n",
    "\n",
    "**`@router.post('/summarize-text')`**\n",
    "- Creates new endpoint: `POST /todos/summarize-text`\n",
    "- Uses POST because we're sending data to be processed\n",
    "- Part of the `/todos` router (your existing structure)\n",
    "\n",
    "**`async def summarize_text(text: str):`**\n",
    "- `async` because AI API calls can take time\n",
    "- `text: str` parameter - FastAPI automatically parses request body\n",
    "- Simple parameter type for easy testing\n",
    "\n",
    "**`summary = summarize_chain.run(text=text)`**\n",
    "- Uses our LangChain setup to process the text\n",
    "- `run()` method executes the entire chain\n",
    "- Returns the AI's summary as a string\n",
    "\n",
    "**Error Handling:**\n",
    "- `try/except` catches any AI API errors\n",
    "- Returns proper HTTP error status (500)\n",
    "- Provides helpful error message for debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Testing the Summarization Feature\n",
    "\n",
    "### Step 1: Start Your Server\n",
    "\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```\n",
    "\n",
    "**‚úÖ Check for Success:**\n",
    "- Server starts without errors\n",
    "- No import or syntax errors in the logs\n",
    "- Your existing endpoints still work\n",
    "\n",
    "### Step 2: Test with FastAPI Docs\n",
    "\n",
    "1. **Open API Documentation**: `http://localhost:8000/docs`\n",
    "2. **Find Your New Endpoint**: Look for `POST /todos/summarize-text`\n",
    "3. **Click \"Try it out\"**\n",
    "4. **Enter Test Text**:\n",
    "\n",
    "```\n",
    "The meeting covered several important topics. First, we discussed the quarterly budget and decided to increase the marketing spend by 15%. Second, we reviewed the hiring timeline for the engineering team and agreed to post the job listings next week. Finally, we set the deadline for the new product launch to be March 15th. The team expressed concerns about the tight timeline but committed to the goal. We also decided to have weekly check-ins to monitor progress.\n",
    "```\n",
    "\n",
    "5. **Click \"Execute\"**\n",
    "\n",
    "**Expected Response:**\n",
    "```json\n",
    "{\n",
    "  \"summary\": \"The meeting discussed increasing marketing spend by 15%, posting engineering job listings next week, and setting a March 15th product launch deadline with weekly progress check-ins.\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Step 3: Test with Different Content\n",
    "\n",
    "**Short Text:**\n",
    "```\n",
    "Buy groceries\n",
    "```\n",
    "*Expected: Brief or same text returned*\n",
    "\n",
    "**Technical Text:**\n",
    "```\n",
    "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints. It provides automatic interactive API documentation, data validation, serialization, and authentication. The framework is built on top of Starlette for the web parts and Pydantic for the data parts.\n",
    "```\n",
    "*Expected: Concise summary of FastAPI's features*\n",
    "\n",
    "### Step 4: Troubleshooting Common Issues\n",
    "\n",
    "**‚ùå Error: \"OpenAI API key not found\"**\n",
    "- Check your `.env` file has `OPENAI_API_KEY=sk-...`\n",
    "- Restart your server after adding the key\n",
    "- Make sure `.env` is in the `backend/` directory\n",
    "\n",
    "**‚ùå Error: \"Rate limit exceeded\"**\n",
    "- Wait a few seconds and try again\n",
    "- Check your OpenAI dashboard for usage limits\n",
    "- Make sure you have billing set up with OpenAI\n",
    "\n",
    "**‚ùå Error: \"Import error for langchain\"**\n",
    "- Make sure you installed `langchain==0.1.1`\n",
    "- Check you're in the right virtual environment\n",
    "- Try `pip list | grep langchain` to verify installation\n",
    "\n",
    "**‚úÖ Success Indicators:**\n",
    "- API returns summarized text\n",
    "- Response time is 2-5 seconds (AI processing takes time)\n",
    "- Summary is shorter and more focused than original\n",
    "- Your existing todo endpoints still work perfectly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Creating the Poem Generation Feature\n",
    "\n",
    "### Step 1: Add Poem Generation Components\n",
    "\n",
    "Add this code **after** your summarization setup:\n",
    "\n",
    "```python\n",
    "# Create prompt template for poem generation\n",
    "write_poem_template_string = \"\"\"\n",
    "        Write a short poem with the following text:\n",
    "        {text}\n",
    "\"\"\"\n",
    "\n",
    "write_poem_prompt = PromptTemplate(\n",
    "    template=write_poem_template_string,\n",
    "    input_variables=['text'],\n",
    ")\n",
    "\n",
    "# Create LLM chain for poem generation\n",
    "write_poem_chain = LLMChain(\n",
    "    llm=langchain_llm,  # Same LLM instance as summarization\n",
    "    prompt=write_poem_prompt,\n",
    ")\n",
    "```\n",
    "\n",
    "**Key Differences from Summarization:**\n",
    "\n",
    "**Creative vs. Factual:**\n",
    "- Poems are creative (we still use `temperature=0` for consistency)\n",
    "- Summaries are factual and focused\n",
    "- Same AI model, different prompt produces different behavior\n",
    "\n",
    "**Reusing LLM Instance:**\n",
    "- We use the same `langchain_llm` for both features\n",
    "- Efficient resource usage\n",
    "- Consistent API connection handling\n",
    "\n",
    "### Step 2: Create the Poem Generation Endpoint\n",
    "\n",
    "This endpoint will be more complex because it needs to:\n",
    "1. Get a specific todo from the database\n",
    "2. Use that todo's content to generate a poem\n",
    "3. Handle cases where the todo doesn't exist\n",
    "\n",
    "```python\n",
    "# Poem generation endpoint\n",
    "@router.post(\"/write-poem/{id}\")\n",
    "async def write_poem_by_id(id: int, db: Session = Depends(get_db)):\n",
    "    try:\n",
    "        # Get the todo from database\n",
    "        todo = crud.read_todo(db, id)\n",
    "        if todo is None:\n",
    "            raise HTTPException(status_code=404, detail=\"Todo not found\")\n",
    "        \n",
    "        # Generate poem from todo content\n",
    "        poem = write_poem_chain.run(text=todo.name)\n",
    "        return {'poem': poem}\n",
    "        \n",
    "    except HTTPException:\n",
    "        # Re-raise HTTP exceptions (like 404)\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Handle AI API errors\n",
    "        raise HTTPException(\n",
    "            status_code=500, \n",
    "            detail=f\"AI poem generation failed: {str(e)}\"\n",
    "        )\n",
    "```\n",
    "\n",
    "**Endpoint Explanation:**\n",
    "\n",
    "**`@router.post(\"/write-poem/{id}\")`**\n",
    "- Creates: `POST /todos/write-poem/123`\n",
    "- `{id}` is a path parameter for the todo ID\n",
    "- Uses POST because it triggers AI processing\n",
    "\n",
    "**`id: int, db: Session = Depends(get_db)`**\n",
    "- `id: int` extracts todo ID from URL path\n",
    "- `db: Session` injects database connection (existing pattern)\n",
    "- Uses your existing `get_db()` function\n",
    "\n",
    "**Database Integration:**\n",
    "- `todo = crud.read_todo(db, id)` uses your existing CRUD function\n",
    "- Follows your established patterns\n",
    "- No new database code needed!\n",
    "\n",
    "**Error Handling:**\n",
    "1. **Todo not found** ‚Üí 404 error (standard REST pattern)\n",
    "2. **AI errors** ‚Üí 500 error with helpful message\n",
    "3. **Re-raise HTTP exceptions** ‚Üí Preserves proper error responses\n",
    "\n",
    "**AI Integration:**\n",
    "- `poem = write_poem_chain.run(text=todo.name)` uses todo content\n",
    "- Returns poem in consistent JSON format\n",
    "- Integrates existing data with new AI capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Testing the Poem Generation Feature\n",
    "\n",
    "### Step 1: Make Sure You Have Todos\n",
    "\n",
    "Before testing poem generation, create a few todos using your existing API:\n",
    "\n",
    "1. **Open FastAPI Docs**: `http://localhost:8000/docs`\n",
    "2. **Use `POST /todos/`** to create test todos:\n",
    "\n",
    "**Test Todo 1:**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Study for math exam\",\n",
    "  \"completed\": false\n",
    "}\n",
    "```\n",
    "\n",
    "**Test Todo 2:**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Finish painting project\",\n",
    "  \"completed\": false\n",
    "}\n",
    "```\n",
    "\n",
    "**Test Todo 3:**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Buy groceries\",\n",
    "  \"completed\": false\n",
    "}\n",
    "```\n",
    "\n",
    "3. **Use `GET /todos/`** to see your todos and note their IDs\n",
    "\n",
    "### Step 2: Test Poem Generation\n",
    "\n",
    "**Find Your New Endpoint**: `POST /todos/write-poem/{id}`\n",
    "\n",
    "**Test with ID 1:**\n",
    "1. Click \"Try it out\"\n",
    "2. Enter `1` for the `id` parameter\n",
    "3. Click \"Execute\"\n",
    "\n",
    "**Expected Response:**\n",
    "```json\n",
    "{\n",
    "  \"poem\": \"Numbers dance across the page,\\nFormulas waiting to be solved,\\nKnowledge grows with every stage,\\nAs mysteries get resolved.\\n\\nEquations hold the key to truth,\\nMath exam approaching near,\\nStudy hard and use your youth,\\nSuccess will soon appear!\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Step 3: Test Different Todo Content\n",
    "\n",
    "**Creative Task (Painting):**\n",
    "- Should generate artistic, colorful poems\n",
    "- Words about creativity, colors, art\n",
    "\n",
    "**Mundane Task (Groceries):**\n",
    "- Should create something fun from ordinary content\n",
    "- Shows AI's ability to find creativity in simple tasks\n",
    "\n",
    "**Academic Task (Study):**\n",
    "- Should generate motivational, focused poems\n",
    "- Educational and encouraging tone\n",
    "\n",
    "### Step 4: Test Error Scenarios\n",
    "\n",
    "**Non-existent Todo ID:**\n",
    "1. Try ID `999` (should not exist)\n",
    "2. Expected response:\n",
    "```json\n",
    "{\n",
    "  \"detail\": \"Todo not found\"\n",
    "}\n",
    "```\n",
    "3. Status code should be `404`\n",
    "\n",
    "**Invalid ID Format:**\n",
    "1. Try ID `abc` (not a number)\n",
    "2. FastAPI should return validation error\n",
    "3. Shows built-in input validation working\n",
    "\n",
    "### Step 5: Verify Integration Works\n",
    "\n",
    "**‚úÖ Success Checklist:**\n",
    "- Poem endpoint finds existing todos correctly\n",
    "- Generated poems relate to todo content\n",
    "- Error handling works for missing todos\n",
    "- Response format is consistent\n",
    "- Your existing todo CRUD still works perfectly\n",
    "- Both AI endpoints (summarize + poem) function\n",
    "\n",
    "**üìä Performance Notes:**\n",
    "- Poem generation takes 2-5 seconds (AI processing time)\n",
    "- Database lookup is instant (uses existing optimized queries)\n",
    "- Total response time is dominated by AI API call\n",
    "- This is normal and expected for AI features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Complete Code Example\n",
    "\n",
    "Here's what your complete `routers/todos.py` file should look like with AI features added:\n",
    "\n",
    "```python\n",
    "from typing import List\n",
    "from sqlalchemy.orm import Session\n",
    "from fastapi import APIRouter, Depends, HTTPException, status\n",
    "import schemas\n",
    "import crud\n",
    "from database import SessionLocal\n",
    "\n",
    "# NEW: LangChain imports\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "router = APIRouter(prefix=\"/todos\")\n",
    "\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# ==========================================\n",
    "# EXISTING CRUD ENDPOINTS (unchanged)\n",
    "# ==========================================\n",
    "\n",
    "@router.post(\"\", status_code=status.HTTP_201_CREATED)\n",
    "def create_todo(todo: schemas.TodoRequest, db: Session = Depends(get_db)):\n",
    "    return crud.create_todo(db, todo)\n",
    "\n",
    "@router.get(\"\", response_model=List[schemas.TodoResponse])\n",
    "def get_todos(completed: bool = None, db: Session = Depends(get_db)):\n",
    "    return crud.get_todos(db, completed=completed)\n",
    "\n",
    "@router.get(\"/{todo_id}\")\n",
    "def get_todo_by_id(todo_id: int, db: Session = Depends(get_db)):\n",
    "    todo = crud.get_todo(db, todo_id)\n",
    "    if todo is None:\n",
    "        raise HTTPException(status_code=404, detail=\"Todo not found\")\n",
    "    return todo\n",
    "\n",
    "@router.put(\"/{todo_id}\")\n",
    "def update_todo(todo_id: int, todo: schemas.TodoRequest, db: Session = Depends(get_db)):\n",
    "    updated_todo = crud.update_todo(db, todo_id, todo)\n",
    "    if updated_todo is None:\n",
    "        raise HTTPException(status_code=404, detail=\"Todo not found\")\n",
    "    return updated_todo\n",
    "\n",
    "@router.delete(\"/{todo_id}\")\n",
    "def delete_todo(todo_id: int, db: Session = Depends(get_db)):\n",
    "    deleted_todo = crud.delete_todo(db, todo_id)\n",
    "    if deleted_todo is None:\n",
    "        raise HTTPException(status_code=404, detail=\"Todo not found\")\n",
    "    return deleted_todo\n",
    "\n",
    "# ==========================================\n",
    "# NEW: LANGCHAIN AI FEATURES\n",
    "# ==========================================\n",
    "\n",
    "# Initialize OpenAI LLM\n",
    "langchain_llm = OpenAI(temperature=0)\n",
    "\n",
    "# Summarization setup\n",
    "summarize_template_string = \"\"\"\n",
    "        Provide a summary for the following text:\n",
    "        {text}\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate(\n",
    "    template=summarize_template_string,\n",
    "    input_variables=['text'],\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(\n",
    "    llm=langchain_llm,\n",
    "    prompt=summarize_prompt,\n",
    ")\n",
    "\n",
    "# Poem generation setup\n",
    "write_poem_template_string = \"\"\"\n",
    "        Write a short poem with the following text:\n",
    "        {text}\n",
    "\"\"\"\n",
    "\n",
    "write_poem_prompt = PromptTemplate(\n",
    "    template=write_poem_template_string,\n",
    "    input_variables=['text'],\n",
    ")\n",
    "\n",
    "write_poem_chain = LLMChain(\n",
    "    llm=langchain_llm,\n",
    "    prompt=write_poem_prompt,\n",
    ")\n",
    "\n",
    "# AI Endpoints\n",
    "@router.post('/summarize-text')\n",
    "async def summarize_text(text: str):\n",
    "    try:\n",
    "        summary = summarize_chain.run(text=text)\n",
    "        return {'summary': summary}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500, \n",
    "            detail=f\"AI summarization failed: {str(e)}\"\n",
    "        )\n",
    "\n",
    "@router.post(\"/write-poem/{id}\")\n",
    "async def write_poem_by_id(id: int, db: Session = Depends(get_db)):\n",
    "    try:\n",
    "        # Get the todo from database\n",
    "        todo = crud.read_todo(db, id)\n",
    "        if todo is None:\n",
    "            raise HTTPException(status_code=404, detail=\"Todo not found\")\n",
    "        \n",
    "        # Generate poem from todo content\n",
    "        poem = write_poem_chain.run(text=todo.name)\n",
    "        return {'poem': poem}\n",
    "        \n",
    "    except HTTPException:\n",
    "        # Re-raise HTTP exceptions (like 404)\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        # Handle AI API errors\n",
    "        raise HTTPException(\n",
    "            status_code=500, \n",
    "            detail=f\"AI poem generation failed: {str(e)}\"\n",
    "        )\n",
    "```\n",
    "\n",
    "### Key Architecture Points\n",
    "\n",
    "**‚úÖ Clean Separation:**\n",
    "- Existing CRUD endpoints unchanged\n",
    "- AI features added as separate section\n",
    "- Both use same router and patterns\n",
    "\n",
    "**‚úÖ Resource Reuse:**\n",
    "- Same `get_db()` dependency\n",
    "- Same error handling patterns\n",
    "- Same router prefix (`/todos`)\n",
    "\n",
    "**‚úÖ LangChain Best Practices:**\n",
    "- Single LLM instance for multiple features\n",
    "- Clear prompt templates\n",
    "- Reusable chains for different tasks\n",
    "- Proper error handling for AI operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Takeaways\n",
    "\n",
    "### What You've Accomplished:\n",
    "\n",
    "1. **üîß Added AI to Existing API**: Enhanced your todo app without breaking existing functionality\n",
    "2. **‚õìÔ∏è Learned LangChain Patterns**: PromptTemplate, LLMChain, and OpenAI integration\n",
    "3. **üöÄ Created Two AI Features**: Text summarization and creative poem generation\n",
    "4. **üíæ Integrated with Database**: AI features work with your existing todo data\n",
    "5. **üõ°Ô∏è Implemented Error Handling**: Robust AI integration with proper error responses\n",
    "6. **üìä Maintained Performance**: Clean, efficient code using modern patterns\n",
    "\n",
    "### LangChain Patterns You Can Reuse:\n",
    "\n",
    "‚úÖ **Single LLM, Multiple Chains**: One OpenAI instance for different AI tasks  \n",
    "‚úÖ **Template-Based Prompts**: Consistent, maintainable AI instructions  \n",
    "‚úÖ **Chain Pattern**: Reusable AI operations with proper error handling  \n",
    "‚úÖ **Database Integration**: Combine existing data with AI processing  \n",
    "‚úÖ **Progressive Enhancement**: Add AI without changing core functionality  \n",
    "\n",
    "### Your New API Endpoints:\n",
    "\n",
    "**üìù Text Summarization:**\n",
    "- `POST /todos/summarize-text` - General-purpose text summarization\n",
    "- Input: Any text string\n",
    "- Output: AI-generated summary\n",
    "\n",
    "**üé≠ Poem Generation:**\n",
    "- `POST /todos/write-poem/{id}` - Creative poems from todo content\n",
    "- Input: Todo ID (uses existing database)\n",
    "- Output: AI-generated poem based on todo text\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "In **Notebook 23**, we'll create the frontend integration:\n",
    "- Add \"Generate Poem\" buttons to your React components\n",
    "- Create popup displays for AI-generated content\n",
    "- Handle loading states and error scenarios\n",
    "- Build a complete AI-enhanced user experience\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've successfully added AI superpowers to your todo app backend. Your existing functionality is unchanged, but now you have powerful AI features that can enhance your users' experience. \n",
    "\n",
    "**Ready to bring these AI features to your users through the frontend? Let's build the React integration in Notebook 23! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}